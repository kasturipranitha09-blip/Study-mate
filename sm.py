# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d-BLd9w9p0-U9RAEHCnkPRDSTHXEQkja
"""

!pip install gradio transformers torch PyPDF2 accelerate

# IBM Granite 3.2 2B Instruct - Multi-Function AI Application
# Run this in Google Colab

# First, install required packages
!pip install transformers torch gradio accelerate

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import re

# Initialize the model and tokenizer
model_name = "ibm-granite/granite-3.2-2b-instruct"

print("Loading model and tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto" if torch.cuda.is_available() else None,
    trust_remote_code=True
)

def generate_response(prompt, max_tokens=512, temperature=0.7):
    """Generate response from the Granite model"""
    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=2048)
        if torch.cuda.is_available():
            inputs = inputs.to('cuda')

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_tokens,
                temperature=temperature,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id,
                repetition_penalty=1.1
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        # Remove the input prompt from the response
        response = response.replace(prompt, "").strip()
        return response
    except Exception as e:
        return f"Error generating response: {str(e)}"

# 1. Smart Text Summarizer
def smart_summarizer(text, focus_mode):
    focus_prompts = {
        "Key Facts Only": "Extract and list only the key facts and important information from the following text:\n\n",
        "Emotional Tone Summary": "Analyze the emotional tone and provide a summary focusing on feelings, attitudes, and emotional elements in the following text:\n\n",
        "Actionable Insights": "Identify actionable insights, recommendations, and next steps from the following text:\n\n"
    }

    prompt = focus_prompts[focus_mode] + text + "\n\nSummary:"
    return generate_response(prompt, max_tokens=300)

# 2. Context-Aware Rewriter
def context_rewriter(text, rewrite_style):
    style_prompts = {
        "Professional Rewrite": "Rewrite the following text in a professional, formal business tone:\n\n",
        "Simplify for Kids": "Rewrite the following text in simple language that a 10-year-old child could easily understand:\n\n",
        "Creative Rewrite (Poetic/Story-like)": "Rewrite the following text in a creative, poetic, or story-like style:\n\n"
    }

    prompt = style_prompts[rewrite_style] + text + "\n\nRewritten text:"
    return generate_response(prompt, max_tokens=400)

# 3. Conversational Knowledge Assistant
def knowledge_assistant(question, answer_style):
    style_prompts = {
        "One-liner Answer": "Answer the following question in one clear, concise sentence:\n\n",
        "Detailed Explanation": "Provide a detailed, comprehensive explanation for the following question:\n\n",
        "Analogy-Based Answer": "Answer the following question using analogies and simple comparisons to explain the concept:\n\n"
    }

    prompt = style_prompts[answer_style] + question + "\n\nAnswer:"
    return generate_response(prompt, max_tokens=400)

# 4. AI Brainstorming Partner
def brainstorming_partner(topic):
    prompt = f"""Help me brainstorm about: {topic}

Please provide:
1. Pros & Cons:
2. 3 Creative Angles:
3. Potential Next Steps:

Topic: {topic}

Brainstorming Output:"""
    return generate_response(prompt, max_tokens=500)

# 5. Email/Message Polisher
def email_polisher(rough_text, tone):
    tone_prompts = {
        "Formal Business Tone": "Rewrite this message in a formal, professional business tone:\n\n",
        "Friendly Casual Tone": "Rewrite this message in a friendly, casual, and approachable tone:\n\n",
        "Crisp & Concise": "Rewrite this message to be crisp, concise, and to-the-point:\n\n"
    }

    prompt = tone_prompts[tone] + rough_text + "\n\nPolished message:"
    return generate_response(prompt, max_tokens=300)

# 6. Story Generator with Style Control
def story_generator(characters_theme_setting, story_style):
    style_prompts = {
        "Sci-fi Version": "Write a science fiction story based on the following elements:\n\n",
        "Mystery Version": "Write a mystery story based on the following elements:\n\n",
        "Comedy Version": "Write a comedy story based on the following elements:\n\n"
    }

    prompt = style_prompts[story_style] + characters_theme_setting + "\n\nStory:"
    return generate_response(prompt, max_tokens=600)

# 7. Custom Prompt Builder
def prompt_builder(goal):
    prompt = f"""The user wants to: {goal}

Help create an optimized prompt that will get better results from AI. Provide:
1. A well-structured prompt
2. Tips for improvement
3. Example of what good output might look like

User goal: {goal}

Optimized prompt and guidance:"""
    return generate_response(prompt, max_tokens=400)

# 8. AI-Powered Debate Mode
def debate_mode(topic):
    prompt = f"""Topic for debate: {topic}

Please provide a balanced analysis with:

*Pro Side (Arguments FOR):*
[List 3-4 strong arguments supporting this position]

*Con Side (Arguments AGAINST):*
[List 3-4 strong arguments opposing this position]

*Balanced Conclusion:*
[A nuanced conclusion that considers both sides]

Topic: {topic}

Debate Analysis:"""
    return generate_response(prompt, max_tokens=600)

# Create the Gradio interface
with gr.Blocks(title="IBM Granite AI Multi-Function App", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üöÄ IBM Granite AI Multi-Function Application")
    gr.Markdown("Powered by IBM Granite 3.2 2B Instruct Model")

    with gr.Tabs():
        # Tab 1: Smart Summarizer
        with gr.TabItem("üìÑ Smart Summarizer"):
            gr.Markdown("### Extract focused summaries from your text")
            with gr.Row():
                with gr.Column():
                    sum_input = gr.Textbox(
                        label="Input Text",
                        placeholder="Paste your long article, PDF text, or any content here...",
                        lines=8
                    )
                    sum_focus = gr.Dropdown(
                        choices=["Key Facts Only", "Emotional Tone Summary", "Actionable Insights"],
                        label="Focus Mode",
                        value="Key Facts Only"
                    )
                    sum_btn = gr.Button("Generate Summary", variant="primary")
                with gr.Column():
                    sum_output = gr.Textbox(label="Summary Output", lines=8)

            sum_btn.click(smart_summarizer, [sum_input, sum_focus], sum_output)

        # Tab 2: Context-Aware Rewriter
        with gr.TabItem("‚úç Text Rewriter"):
            gr.Markdown("### Rewrite your text in different styles")
            with gr.Row():
                with gr.Column():
                    rewrite_input = gr.Textbox(
                        label="Original Text",
                        placeholder="Paste the paragraph you want to rewrite...",
                        lines=6
                    )
                    rewrite_style = gr.Dropdown(
                        choices=["Professional Rewrite", "Simplify for Kids", "Creative Rewrite (Poetic/Story-like)"],
                        label="Rewrite Style",
                        value="Professional Rewrite"
                    )
                    rewrite_btn = gr.Button("Rewrite Text", variant="primary")
                with gr.Column():
                    rewrite_output = gr.Textbox(label="Rewritten Text", lines=8)

            rewrite_btn.click(context_rewriter, [rewrite_input, rewrite_style], rewrite_output)

        # Tab 3: Knowledge Assistant
        with gr.TabItem("üß† Knowledge Assistant"):
            gr.Markdown("### Ask questions and get answers in your preferred style")
            with gr.Row():
                with gr.Column():
                    qa_input = gr.Textbox(
                        label="Your Question",
                        placeholder="Ask any question about any topic...",
                        lines=3
                    )
                    qa_style = gr.Dropdown(
                        choices=["One-liner Answer", "Detailed Explanation", "Analogy-Based Answer"],
                        label="Answer Style",
                        value="Detailed Explanation"
                    )
                    qa_btn = gr.Button("Get Answer", variant="primary")
                with gr.Column():
                    qa_output = gr.Textbox(label="Answer", lines=8)

            qa_btn.click(knowledge_assistant, [qa_input, qa_style], qa_output)

        # Tab 4: Brainstorming Partner
        with gr.TabItem("üí° Brainstorming"):
            gr.Markdown("### Generate ideas, pros & cons, and next steps")
            with gr.Row():
                with gr.Column():
                    brain_input = gr.Textbox(
                        label="Topic or Idea",
                        placeholder="Enter your topic, business idea, or concept to brainstorm...",
                        lines=3
                    )
                    brain_btn = gr.Button("Start Brainstorming", variant="primary")
                with gr.Column():
                    brain_output = gr.Textbox(label="Brainstorming Results", lines=12)

            brain_btn.click(brainstorming_partner, brain_input, brain_output)

        # Tab 5: Email Polisher
        with gr.TabItem("üìß Email Polisher"):
            gr.Markdown("### Polish your emails and messages")
            with gr.Row():
                with gr.Column():
                    email_input = gr.Textbox(
                        label="Rough Email/Message",
                        placeholder="Paste your draft email or message here...",
                        lines=6
                    )
                    email_tone = gr.Dropdown(
                        choices=["Formal Business Tone", "Friendly Casual Tone", "Crisp & Concise"],
                        label="Desired Tone",
                        value="Formal Business Tone"
                    )
                    email_btn = gr.Button("Polish Message", variant="primary")
                with gr.Column():
                    email_output = gr.Textbox(label="Polished Message", lines=8)

            email_btn.click(email_polisher, [email_input, email_tone], email_output)

        # Tab 6: Story Generator
        with gr.TabItem("üìö Story Generator"):
            gr.Markdown("### Create stories in different genres")
            with gr.Row():
                with gr.Column():
                    story_input = gr.Textbox(
                        label="Characters, Theme, or Setting",
                        placeholder="Describe characters, theme, setting, or basic story elements...",
                        lines=4
                    )
                    story_style = gr.Dropdown(
                        choices=["Sci-fi Version", "Mystery Version", "Comedy Version"],
                        label="Story Style",
                        value="Sci-fi Version"
                    )
                    story_btn = gr.Button("Generate Story", variant="primary")
                with gr.Column():
                    story_output = gr.Textbox(label="Generated Story", lines=12)

            story_btn.click(story_generator, [story_input, story_style], story_output)

        # Tab 7: Prompt Builder
        with gr.TabItem("üîß Prompt Builder"):
            gr.Markdown("### Get better AI results with optimized prompts")
            with gr.Row():
                with gr.Column():
                    prompt_input = gr.Textbox(
                        label="Your Goal",
                        placeholder="Describe what you want to achieve with AI (e.g., 'write a LinkedIn post', 'analyze data', etc.)",
                        lines=3
                    )
                    prompt_btn = gr.Button("Build Optimized Prompt", variant="primary")
                with gr.Column():
                    prompt_output = gr.Textbox(label="Optimized Prompt & Tips", lines=10)

            prompt_btn.click(prompt_builder, prompt_input, prompt_output)

        # Tab 8: Debate Mode
        with gr.TabItem("‚öñ Debate Mode"):
            gr.Markdown("### Explore multiple perspectives on any topic")
            with gr.Row():
                with gr.Column():
                    debate_input = gr.Textbox(
                        label="Debate Topic",
                        placeholder="Enter a topic for debate (e.g., 'Is AI good for jobs?', 'Should social media be regulated?')",
                        lines=3
                    )
                    debate_btn = gr.Button("Generate Debate Analysis", variant="primary")
                with gr.Column():
                    debate_output = gr.Textbox(label="Debate Analysis", lines=12)

            debate_btn.click(debate_mode, debate_input, debate_output)

    gr.Markdown("---")
    gr.Markdown("Built with IBM Granite 3.2 2B Instruct and Gradio")

# Launch the app
if __name__ == "__main__":
    print("Starting IBM Granite AI Application...")
    demo.launch(
        share=True,  # Creates a public link
        debug=True,
        server_name="0.0.0.0",
        server_port=7860
    )

